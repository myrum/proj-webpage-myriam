<html>
	<head>
	</head>
	<body>
		<h2> Task 1 </h2>
		<b>Walk through how you rasterize triangles in your own words.</b>
		
		<p> Simply put, rasterizing a triangle is the process of finding the lines and points that make up the triangle and then testing whether each pixel is inside the triangle or not. If it is, then we render it and if it is not then we leave it alone.</p>
	
		<b>Explain how your algorithm is no worse than one that checks each sample within the bounding box of the triangle. </b>
		
		<p> My algorithm is based off of the point in triangle test from the lecture 2 slides. The boundary box is created by taking the points and finding the min and max coodinartes for the 2 for loops (x & y). This helps avoid checking every pixel on the screen, which would make it slower. Then after all of the checks are done, I call fill_pixel() if the pixel passed the test.</p>
		
		
		<b>Show a png screenshot of basic/test4.svg with the default viewing parameters and with the pixel inspector centered on an interesting part of the scene.</b>
		<img src="./screenshot_2-13_15-9-41.png">
		
		<h2> Task 2 </h2>
		
		<b> Walk through your supersampling algorithm and data structures. Why is supersampling useful? What modifications did you make to the rasterization pipeline in the process? Explain how you used supersampling to antialias your triangles.</b>
		<p> My algorithm modifies the rasterize_triangle from task 1 by adding in 2 extra for loops to sample more pixels based on the sample rate (for ex. 2x2 would have pixels at offsets of 1/4 and 3/4). The offets for each sample rate are calculated based on the index and the base fraction of 0.5 / sqrt(sample_rate). The same point in triangle test occurs with each point and they are added to the sample buffer (which has been resized to be width * height * sample_rate) if they pass. Then, once all the subpixels are sampled, I went into resolve_to_framebuffer to average the color by adding up all of the subpixel colors and then dividing r,g,b by sqrt(sample_rate). rgb_framebuffer_target is then set to each color channel (current index + 0 is r, current index + 1 is g, and current index + 2 is b). Supersampling is useful for when you want to blur the edges of an image more so that it looks less jagged (i.e. helps get rid of jaggies). Through supersampling, I can average out the pixels' colors into something that looks more smooth. Instead of each pixel only being able to be one solid color, they can be a blend of multiple colors, which makes the edges stand out less.  </p>		
		
		<b> Show png screenshots of basic/test4.svg with the default viewing parameters and sample rates 1, 4, and 16 to compare them side-by-side. Position the pixel inspector over an area that showcases the effect dramatically; for example, a very skinny triangle corner. Explain why these results are observed.</b>
		<p> sample rate = 1 - normal sampling, have  a lot of jaggies because there is no blending </p>
		<img src="./screenshot_2-14_14-20-31.png">
		<p> sample rate = 4 - the edges are more straight here because sampling the subpixels</p>
		<img src="./screenshot_2-14_14-20-37.png">
		<p> sample rate = 16 - the edges are blurred a little bit, you can see that the color is a mix of the magenta and white background.</p>
		<img src="./screenshot_2-14_14-20-42.png">
		
		<h2> Task 3</h2>
		
		<b> Create an updated version of svg/transforms/robot.svg with cubeman doing something more interesting, like waving or running. Feel free to change his colors or proportions to suit your creativity. Save your svg file as my_robot.svg in your docs/ directory and show a png screenshot of your rendered drawing in your write-up. Explain what you were trying to do with cubeman in words. </b>
		<img src="./screenshot_2-14_18-16-9.png">
		<p> I edited the two rectangle arms of the robot so that it looks like it's waving. I rotated the left rectangles by 90 and then translated them so that they were parallel to the torso. Then I rotated the right upper arm by -45 and the lower arm by 90 and translated them accordingly.</p>
	
		<h2> Task 4 </h2>
		
		<b> Explain barycentric coordinates in your own words and use an image to aid you in your explanation. One idea is to use a svg file that plots a single triangle with one red, one green, and one blue vertex, which should produce a smoothly blended color triangle. </b>
		<p> Barycentric coordinates are a coordinate system with respect to a triangle. They maintain proportionality as the coefficient of the equation for barycentric coordinates have to add up to one. In the image below, each corner of the triangle represents a different color, whihc means that each color can be a barycentric coordinate. Since there's 3 colors and 3 points on the rectangle, the barycentric coefficients signify how much of each color triangle has. Thus when we insert the coefficients into the equation that combines them we end up with a color blend (since alpha, beta, and gamma, have to add up to 1, we don't end up with a situation where </p>
		<img src="./screenshot_2-14_23-5-0.png">
		
		<b> Show a png screenshot of svg/basic/test7.svg with default viewing parameters and sample rate 1. If you make any additional images with color gradients, include them. </b>
		<img src="./screenshot_2-14_21-56-8.png">
		
		<h2> Task 5 </h2>
		<b> Explain pixel sampling in your own words and describe how you implemented it to perform texture mapping. Briefly discuss the two different pixel sampling methods, nearest and bilinear. </b>
		<p> Pixel sampling is the process of taking a pixel and analyzing it in terms of what it will represent on the screen. Nearest sampling is very strict in that it chooses a point's "nearest neighbor" as it's output value while bilinear filtering takes into account all neighbors and averages them accordingly.</p>
		<p> In order to do texture mapping I took the code from task 4 and updated it to use barycentric coordinates for p_uv, p_dx, and p_dy to get the uv space coordinates. Once the coordinates are found I set them in the variable SampleParams sp. Then I called tex.sample(sp) in order to obtain what the pixel would be mapped to. Sample_nearest takes each coordinate and multiplies x by mip.width - 1 and y by mip.height - 1 and then call mip.get_texel(x, y). Sample_bilinear uses lerp to average the color from the nearest 4 points by calling get_texel on each one.</p>
		
		<b> Check out the svg files in the svg/texmap/ directory. Use the pixel inspector to find a good example of where bilinear sampling clearly defeats nearest sampling. Show and compare four png screenshots using nearest sampling at 1 sample per pixel, nearest sampling at 16 samples per pixel, bilinear sampling at 1 sample per pixel, and bilinear sampling at 16 samples per pixel. </b>
		<p> nearest sr = 1 </p> 
		<img src="./screenshot_2-15_22-8-18.png">
		
		<p> bilinear sr = 1 </p> 
		<img src="./screenshot_2-15_22-8-20.png">
		
		<p> nearest sr = 16 </p> 
		<img src="./screenshot_2-15_22-8-35.png">
		
		<p> bilinear sr = 16 </p> 
		<img src="./screenshot_2-15_22-8-37.png">
		
		<b> Comment on the relative differences. Discuss when there will be a large difference between the two methods and why. </b>
		<p> We can see that the "E" in the logo looks more defined when using bilinear sampling and more jagged/blurry when using nearest. There will be a large difference between the two when it comes to more detailed textures are bilinear will take into account the surrounding neighbors while nearest will only choose one. This will result in details being more preserved with bilinear sampling and replaced/overwritten with nearest sampling.</p>
		
		<h2> Task 6</h2>
		
		<b> Explain level sampling in your own words and describe how you implemented it for texture mapping. </b>
		<p> Level sampling is taking advantage of the different levels stored on mip maps and finding the optimal one to use for your image. In get_level, I used the equation in the lecture slide (lec. 5) to calculate mip map level d. From there, I clamped d to be between 0 and the largest mip map level inputted that level to nearest and bilinear. For trilinear, I used the floor and ceil of d and then calculated the percentage of how much of each to mix together.</p>
		
		<b> You can now adjust your sampling technique by selecting pixel sampling, level sampling, or the number of samples per pixel. Describe the tradeoffs between speed, memory usage, and antialiasing power between the three various techniques. </b>
		<p> For pixel sampling, it's pretty fast and simple to compute point sampling but there isn't any antialiasing power while supersampling takes longer to compute and more memory to store but has antialiasing power and look smoother than point sampling. For level sampling, mip maps are useful because they are precalculated and have a lot of antialiasing power but they do take up more memory because they have to store each level. Increasing the number of samples per pixel allows for antialiasing but you must do more calculations and store each one which decreasing the number of samples leads to less antialiasing but saves on memory and computation. Overall, the more antialiasing power you want or detail in your image, the more you will have to calculate and store to make it happen.</p>
		
		<b> Using a png file you find yourself, show us four versions of the image, using the combinations of L_ZERO and P_NEAREST, L_ZERO and P_LINEAR, L_NEAREST and P_NEAREST, as well as L_NEAREST and P_LINEAR.</b>
		<p> level 0, nearest </p>
		<img src="./screenshot_2-15_23-42-6.png">
		<p> level bilinear, nearest</p>
		<img src="./screenshot_2-15_23-42-35.png">
		<p> level nearest, bilinear</p>
		<img src="./screenshot_2-15_23-42-43.png">
		<p> level bilinear, bilinear</p>
		<img src="./screenshot_2-15_23-42-51.png">
		
		<a href="https://myrum.github.io/proj-webpage-myriam/proj1/index.html"> Website Link </a>
	</body>
</html>
